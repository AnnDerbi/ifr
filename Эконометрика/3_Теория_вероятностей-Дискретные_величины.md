# Определение вероятности и основные теоремы
**Пространством элементарных событий** $\Omega$ будем называть множество всех возможных исходов вероятностного эксперимента.

**Вероятностью** на пространстве элементарных событий $\Omega$ называется функция $\mathbb{P}$, которая каждому подмножеству $A$ пространства $\Omega$ ставит в соответствие число $\mathbb{P}(A)$ из отрезка $[0;1]$, удовлетворяющая следующим двум условиям:
1. $\mathbb{P}(\Omega) = 1$
2. Для любых подмножеств $A$ и $B$ множества $\Omega$, для которых $A \cap B = \emptyset$, выполнено $\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B)$

**Свойства вероятности:**
1. $\mathbb{P}(\emptyset) = 0$
2. Если $A \subseteq B$, то $\mathbb{P}(B \textbackslash A) = \mathbb{P}(B) - \mathbb{P}(A)$
3. Если $A \subseteq B$, то $\mathbb{P}(B) \le \mathbb{P}(A)$
4. $\mathbb{P}(A^C) = 1 - \mathbb{P}(A)$, где $A^C := \Omega \textbackslash A$
5. $\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A \cap B)$

События $A$ и $B$ называются **несовместимыми**, если $A \cap B = \emptyset$

События $A$ и $B$ называются **независимыми**, если $\mathbb{P}(A \cap B) = \mathbb{P}(A) \cdot \mathbb{P}(B)$

Пусть $\mathbb{P}(B) \not= 0$. Тогда **условной вероятностью события $A$ при условии события** $B$ называется
$$\mathbb{P}(A|B)=\frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)}$$

Отсюда $\mathbb{P}(A \cap B) = \mathbb{P}(A|B) \cdot \mathbb{P}(B)$

**Теорема умножения вероятностей:** пусть $\mathbb{P}(A_1 \cap ... \cap A_n) \not= 0$, где $n \ge 2$. Тогда 
$\mathbb{P}(A_1 \cap ... \cap A_n) = \mathbb{P}(A_1) \cdot \mathbb{P}(A_2|A_1) \cdot \mathbb{P}(A_n|A_1 \cap ... \cap A_{n-1})$.

**Полной группой событий** называется такой набор множеств $D_1, ...,D_n$, что
1. $D_i \cap D_j = \emptyset$ , при $i \not= j$
2. $D_1 \cup ... \cup D_n = \Omega$.

**Формула полной вероятности:** пусть $D_1, ...D_n$ образуют полную группу событий и $\mathbb{P}(D_i) \not= 0$ для всех $i=1, ..., n$. Тогда $\mathbb{P}(A)=\mathbb{P}(A|D_1) \cdot \mathbb{P}(D_1) + ... +\mathbb{P}(A|D_n) \cdot \mathbb{P}(D_n)$

**Формула Байеса:** пусть $D_1, ...D_n$ образуют полную группу событий и $\mathbb{P}(D_i) \not= 0$ для всех $i=1, ..., n$ и $\mathbb{P}(A) \not= 0$. Тогда для любого $k=1,...n$ справедлива формула:
$$\mathbb{P}(D_k|A)=\frac{\mathbb{P}(A|D_k) \cdot \mathbb{P}(D_k)}{\mathbb{P}(A|D_1) \cdot \mathbb{P}(D_1) + ... +\mathbb{P}(A|D_n) \cdot \mathbb{P}(D_n)}$$
# Случайные величины
Пусть задано пространство элементарных исходов $\Omega$. **Случайной величиной** $X$ называется функция $X=X(\omega)$, которая каждому элементарному событию $\omega$ из пространства элементарных исходов $\Omega$ ставит в соответствие некоторое действительное число $X(\omega)$.

Случайная величина называется **дискретной**, если множество значений, которое она принимает, является конечным или счётным.

Пусть случайная величина $X$ принимает значения $a_1, ..., a_n$. **Таблицей распределения случайной величины** называется таблица вида:

| $X$            | $a_1$                 | $...$ | $a_n$                 |
| -------------- | --------------------- | ----- | --------------------- |
| $\mathbb{P}_X$ | $\mathbb{P}({X=a_1})$ | $...$ | $\mathbb{P}({X=a_n})$ |
# Функция распределения
**Функцией распределения случайной величины** $X$ называется функция $F_X(x)=\mathbb{P}(X \le x)$.

**Свойства функции распределения:**
1. $F_X(x) \in [0;1]$ для любого $x \in \mathbb{R}$.
2. Функция распределения является нестрого возрастающей функцией, т.е. если $x_1 \le x_2$, то $F_X(x_1) \le F_X(x_2)$.
3. $\lim\limits_{x \to -\infty}F_X=0$, $\lim\limits_{x \to +\infty}F_X=1$.
4. $\mathbb{P}(\{a < X \le b\}) = F_X(b) - F_X(a)$ для любых $a < b$.
# Математическое ожидание
Пусть случайная величина $X$ принимает значения $a_1,...,a_n$. Тогда **математическим ожиданием случайной величины** $X$ называется число $\mathbb{E}[X]=a_1 \cdot \mathbb{P}(\{X=a_1\}) + ... + a_n \cdot \mathbb{P}(\{X=a_n\})$

**Свойства математического ожидания.** Пусть $X$ и $Y$ - случайные величины, $c$ - константна, тогда:
1. $\mathbb{E}[c] = c$
2. $\mathbb{E}[cX] = c \cdot \mathbb{E}[X]$
3. $\mathbb{E}[X+Y] = \mathbb{E}[X] + \mathbb{E}[Y]$
4. Если $X$ - неотрицательная случайная величина, то $\mathbb{E}[X] \ge 0$
5. Если $X \le Y$, то $\mathbb{E}[X] \le \mathbb{E}[Y]$
6. $|\mathbb{E}[X]| = \mathbb{E}[|X|]$

Пусть случайная величина $X$ принимает значения $a_1,...,a_n$ и $g(x)$ - некоторая числовая функция. Тогда **математическое ожидание случайной величины** $g(x)$ можно найти по формуле: $\mathbb{E}[g(X)]=g(a_1) \cdot \mathbb{P}(\{X=a_1\}) + ... + g(a_n) \cdot \mathbb{P}(\{X=a_n\})$.

# Дисперсия
**Дисперсией случайной величины** $X$ называется число $D(X) = \mathbb{E}[(X-\mathbb{E}[X])^2]$. Также используется обозначение $Var(x)$ от Variance.

Дисперсия - среднеквадратическая мера разброса значений случайной величины относительно её математического ожидания.

Альтернативная формула: $D(X) = \mathbb{E}(X^2) - (\mathbb{E}X)^2$

**Свойства дисперсии.** Пусть $X$ и $Y$ - случайные величины, $c$ - константна, тогда:
1. $D(X) \ge 0$
2. $D(c) = 0$
3. $D(c \cdot X) = c^2 \cdot D(X)$
4. $D(X + c) = D(X)$
5. Если $D(X)=0$, то $X$ - константна.

Говорят, что случайная величина $X$ имеет **распределение Бернулли** с параметром $p \in (0; 1)$ и пишут $X \sim Be(p)$, если случайная величина $X$ принимает значения $0$ и $1$ с вероятностями $\mathbb{P}(\{X=0\})=1-p$, $\mathbb{P}(\{X=1\})=p$.

# Независимость случайных величин
Случайные величины $X$ и $Y$ называются **независимыми**, если для любых множеств $B \subseteq \mathbb{R}$ и $C \subseteq \mathbb{R}$ справедливо равенство $\mathbb{P}(\{X \in B\} \cap \{Y \in C\}) = \mathbb{P}(\{X \in B\}) \cdot \mathbb{P}(\{Y \in C\})$.

**Критерий независимости**. Пусть случайная величина $X$ принимает значения $a_1,...a_m$, а случайная величина $Y$ принимает значения $b_1,...,b_n$. Тогда случайные величины $X$ и $Y$ являются независимыми в том и только том случае, когда для любого $i \in \{1,...,m\}$ и для любого $j \in \{1,...,n\}$ справедливо равенство $$\mathbb{P}(\{X = a_i\} \cap \{Y = b_j\}) = \mathbb{P}(\{X = a_i\}) \cdot \mathbb{P}(\{Y = b_j\})$$
Если случайные величины $X$ и $Y$ независимы, то $\mathbb{E}[XY]=\mathbb{E}[X] \cdot \mathbb{E}[Y]$.

Пусть случайная величина $X$ принимает значения $a_1,...a_m$, а случайная величина $Y$ принимает значения $b_1,...,b_n$. **Таблицей совместного распределения** случайных величин $X$ и $Y$ называется таблица

|         | $Y=b_1$ | $...$ | $Y=b_j$                                    | $...$ | $Y=b_m$ |
| ------- | ------- | ----- | ------------------------------------------ | ----- | ------- |
| $X=a_1$ |         |       |                                            |       |         |
| $...$   |         |       |                                            |       |         |
| $X=a_i$ |         |       | $\mathbb{P}(\{X = a_i\} \cap \{Y = b_j\})$ |       |         |
| $...$   |         |       |                                            |       |         |
| $X=a_m$ |         |       |                                            |       |         |

Пусть случайная величина $X$ принимает значения $a_1,...a_m$, а случайная величина $Y$ принимает значения $b_1,...,b_n$ и пусть $g(x, y)$ -числовая функция. Тогда математическое ожидание случайной величины $g(X, Y)$ можно найти по формуле $$\mathbb{E}[g(X,Y)] = \sum_{i=1}^m \sum_{j=1}^n g(a_i, b_j) \cdot \mathbb{P}\{X=a_i\} \cap \{Y=b_j\})$$ 
# Ковариация
**Ковариацией случайных величин $X$ и $Y$** называется $cov(X,Y) = \mathbb{E}[(X-\mathbb{E}X)(Y-\mathbb{E}Y)]$.

Ковариация - мера линейной зависимости между случайными величинами. Если она нулевая, то связь отсутствует. Она находится в диапазоне $(-\infty;+\infty)$.


Ковариация может быть вычислена по формуле:
$$cov(X,Y) = \mathbb{E}[XY] - \mathbb{E}[X] \cdot \mathbb{E}[Y]$$

**Свойства ковариации.** Пусть $X$, $Y$, $Z$ - случайные величины, а $c$ - константа, тогда:
1. $cov(X,X) = D(X)$
2. $cov(X,Y) = cov(Y,X)$
3. $cov(X+Y,Z) = cov(X,Z) + cov(Y,Z)$
4. $cov(X,Y+Z) = cov(X,Y) + cov(X,Z)$
5. $cov(cX,Y) = c \cdot cov(X,Y)$
6. $cov(X,cY) = c \cdot cov(X,Y)$
7. $cov(X, c) = 0$
8. $cov(c, Y) = 0$
9. $cov(X+c, Y) = cov(X,Y)$
10. $cov(X, Y+c) = cov(X,Y)$
11. $D(X \pm Y)=D(X) +D(Y) \pm 2cov(X,Y)$
12. Если $X$ и $Y$ независимы, то $cov(X,Y) = 0$
13. Если $X$ и $Y$ независимы, то $D(X \pm Y) = D(X) \pm D(Y)$
14. $|cov(X,Y)| \le \sqrt{D(X)} \cdot \sqrt{D(Y)}$

Если $cov(X,Y) = 0$, то случайные величины $X$ и $Y$ называются **некоррелированными**. В противном случае они называются **коррелированными**.
Если при этом $cov(X,Y)>0$, то говорят, что случайные величины $X$ и $Y$ **положительно коррелированы**, а если $cov(X,Y)<0$, то $X$ и $Y$ называют **отрицательно коррелированными**.

Пусть случайные величины $X$ и $Y$ имеют конечные дисперсии, тогда:
1. $X$ и $Y$ - коррелированы, $\Rightarrow$ $X$ и $Y$ - зависимы
2. $X$ и $Y$ - коррелированы, $\not\Leftarrow$ $X$ и $Y$ - зависимы
3. $X$ и $Y$ - независимы $\Rightarrow$ $X$ и $Y$ - некоррелированы
4. $X$ и $Y$ - независимы $\not\Leftarrow$ $X$ и $Y$ - некоррелированы

# Корреляция
Пусть $D(X)>0$ и $D(Y)>0$. Тогда **корреляцией случайных величин $X$ и $Y$** называется число
$$corr(X,Y)=\frac{cov(X,Y)}{\sqrt{D(X)} \cdot \sqrt{D(Y)}}$$
Если $D(X)=0$ или $D(Y) = 0$, то по определению считаем, что $corr(X,Y)=0$.

Корреляция - нормированная мера линейной зависимости между случайными величинами - она находится в диапазоне $[-1;1]$.

**Свойства корреляции.** Пусть $X$ и $Y$ - случайные величины, а $a, b, c$ - константы, тогда:
1. $|corr(X,Y)| \le 1$
2. Если $X$, $Y$ - независимы, то $corr(X,Y)=0$
3. $|corr(X,Y)| = 1$ тогда и только тогда, когда существует $a \not= 0$ и $b$, такие, что $Y = a \cdot X + b$. Если $a>0$, то $corr(X,Y) = 1$, если $a<0$, то $|corr(X,Y)| = -1$.
4. $corr(X,Y) = corr(Y,X)$
5. $corr(X+c,Y) = corr(X,Y)$
6. $corr(X,Y+c) = corr(X,Y)$
7. $corr(aX,Y)=\left\{\begin{aligned}corr(X,Y),\ &если\ a>0, \\ 0,\ &если\ a=0 \\-corr(X,Y),\ &если\ a<0\end{aligned}\right.$
8. $corr(X,bY)=\left\{\begin{aligned}corr(X,Y),\ &если\ b>0, \\ 0,\ &если\ b=0 \\-corr(X,Y),\ &если\ b<0\end{aligned}\right.$
